{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e6e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack \n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, auc, RocCurveDisplay, classification_report, ConfusionMatrixDisplay, RocCurveDisplay, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Input \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers  import Conv1D  \n",
    "from tensorflow.keras.utils import plot_model \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers  import MaxPooling1D\n",
    "\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import  LSTM, GRU, SimpleRNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6435ee",
   "metadata": {},
   "source": [
    "# DATASET PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb176c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath): \n",
    "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "\treturn dataframe.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297dd2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list() \n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "        \n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = np.concatenate(loaded)\n",
    "\treturn loaded     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7cddfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group():\n",
    "\tfilepath = \"C:\\\\Users\\\\vvsat\\\\Documents\\\\machine learning\\\\parkinsons speech\\\\\"\n",
    "    \n",
    "\t# load all files as a single array\n",
    "\tfilenames = list()\n",
    "    \n",
    "\tfilenames = ['dataset.txt'] \n",
    "    \n",
    "\t# load input data\n",
    "\tX = load_group(filenames, filepath)\n",
    "    \n",
    "    \n",
    "\t# load class output\n",
    "\t# load input data\n",
    "\ty = load_file(\"C:\\\\Users\\\\vvsat\\\\Documents\\\\machine learning\\\\parkinsons speech\\\\target.txt\")\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df32d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    \n",
    "\tX, y = load_dataset_group()\n",
    "\tprint(X.shape, y.shape) \n",
    "       \n",
    "\t# load all train\n",
    "\ttrainX, testX, trainy, testy = train_test_split(X, y, test_size=0.125, random_state=27) \n",
    "    \n",
    "\t# zero-offset class values\n",
    "\ttrainy = trainy - 1\n",
    "\ttesty = testy - 1\n",
    "    \n",
    "\t# one hot encode y\n",
    "\ttrainy = to_categorical(trainy)\n",
    "\ttesty = to_categorical(testy) \n",
    "    \n",
    "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "\treturn trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8a71ea",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf7ab9",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa457fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "   \n",
    "    # hyperparameter\n",
    "    hp_dropout = hp.Choice('drop_out', values=[0.2, 0.3, 0.5, 0.7, 0.8]) \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.0001, 0.001, 0.01, 0.05, 0.1])\n",
    "    \n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], trainy.shape[0]\n",
    "    print(n_timesteps, n_features, n_outputs)\n",
    "   \n",
    "    print(\"trainX shape : \",trainX.shape)\n",
    "    print(\"trainy shape : \",trainy.shape)  \n",
    "    \n",
    "    #Build the LSTM model \n",
    "    # LSTM Layer returns whole_seq_output, final_memory_state, and final_carry_state \n",
    "    model = Sequential()\n",
    "    model.add(GRU(64, return_sequences=True, input_shape=(None, 1)))\n",
    "    model.add(GRU(128, return_sequences= True))    \n",
    "    model.add(Dropout(rate = hp_dropout)) \n",
    "    \n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(LSTM(256, return_sequences= True))    \n",
    "    model.add(Dropout(rate = hp_dropout)) \n",
    "    \n",
    "    model.add(SimpleRNN(256, return_sequences= False))    \n",
    " \n",
    "    model.add(Dense(2)) \n",
    "    model.summary()  \n",
    "\n",
    "    # learning rate decay\n",
    "    initial_learning_rate = hp_learning_rate\n",
    "    \n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    "    )\n",
    "\n",
    "    # Compile the model \n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=lr_schedule), \n",
    "                  loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy']) \n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364eb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a hyperband tuner using keras tuner \n",
    "tuner = kt.Hyperband(model_builder, \n",
    "                     objective='accuracy', \n",
    "                     max_epochs=10, \n",
    "                     hyperband_iterations=10,        \n",
    "                     factor=50,\n",
    "                     directory='pd_speech_gru',\n",
    "                     project_name='intro_to_kt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3456a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping callback to stop the model when the loss shoots up \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, mode = 'auto', restore_best_weights=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256994ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "\n",
    "#run the hyperband tuner    \n",
    "tuner.search(trainX, trainy, callbacks=[stop_early])  \n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "#printing the optimal hyperparameter values\n",
    "print('best dropout', best_hps.get('drop_out'))\n",
    "print('best learning rate', best_hps.get('learning_rate'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87dfc1f",
   "metadata": {},
   "source": [
    "   # TRAINING THE  MODEL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "trainX, trainy, testX, testy = load_dataset()\n",
    "    \n",
    "verbose, epochs, batch_size = 0, 10, 32\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[0], trainX.shape[1], trainy.shape[0]\n",
    "print(n_timesteps, n_features, n_outputs)\n",
    "   \n",
    "print(\"trainX shape : \",trainX.shape)\n",
    "print(\"trainy shape : \",trainy.shape)  \n",
    "    \n",
    "#Build the LSTM model \n",
    "# LSTM Layer returns whole_seq_output, final_memory_state, and final_carry_state \n",
    "model = Sequential()\n",
    "model.add(GRU(64, return_sequences=True, input_shape=(None, 1)))\n",
    "model.add(GRU(128, return_sequences= True))    \n",
    "    \n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences= True))    \n",
    "model.add(Dropout(rate = hp_dropout)) \n",
    "    \n",
    "model.add(SimpleRNN(256, return_sequences= False))    \n",
    " \n",
    "model.add(Dense(2)) \n",
    "model.summary()  \n",
    "# learning rate decay\n",
    "initial_learning_rate = best_hps.get('learning_rate')\n",
    "    \n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "       initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    "       )\n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=lr_schedule), \n",
    "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the model  \n",
    "history = model.fit(trainX, \n",
    "                    trainy, \n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135d5b58",
   "metadata": {},
   "source": [
    "# SAVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('gru.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b74034",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('gru.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f562125",
   "metadata": {},
   "source": [
    "# PLOTTING THE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e146608",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy'] \n",
    "train_loss = history.history['loss'] \n",
    "#val_acc = history.history['val_accuracy'] \n",
    "#val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(train_acc))  \n",
    "\n",
    "plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
    "#plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss') \n",
    "#plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b2815",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087dc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(testX, testy, batch_size=32)\n",
    "print(\"test loss, test acc:\", results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(testX) \n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(testy, axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcdc2c7",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416310eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363f339",
   "metadata": {},
   "source": [
    "# DISPLAYING PRECISION, RECALL AND AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision score : ', precision_score(y_test, y_pred, average = 'micro'),\n",
    "      '\\n', 'recall score : ', recall_score(y_test, y_pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr) \n",
    "roc_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b889b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
